{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO+99nXWcczTqjInRzRus03",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RatanakamonS/DADS6003-2024-S_RTNKMN/blob/main/HW2(DADS6003)_6620422002_Ratanakamon_Somklang.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6620422002 Ratanakamon Somklang"
      ],
      "metadata": {
        "id": "J02s8aklPK6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Implement SGD, Mini-Batch from https://github.com/ekaratnida/Applied-machine-learning/blob/master/Week03-MLR/Lab3.ipynb"
      ],
      "metadata": {
        "id": "jNz7fjOeq8eA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "c-d1GNQjTSlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[2, 3, 6, 2], [5, 9, 7, 2], [1, 4, 2, 1], [8, 5, 3, 5]])  # Features x1, x2, x3, x4\n",
        "y = np.array([12, 9, 6, 7]).reshape(-1, 1)  # Labels"
      ],
      "metadata": {
        "id": "jtkasAoLCd4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Stochastic Gradient Descent (sampling: N=1)"
      ],
      "metadata": {
        "id": "s-IJtXs1qm8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_function(theta, x, y):\n",
        "    y_hat = x.dot(theta)\n",
        "    c = (1/len(y)) * np.sum((y_hat - y) ** 2)\n",
        "    return c"
      ],
      "metadata": {
        "id": "xqTo_TWrTVyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stochastic_gradient_descent(alpha, x, y, ep=0.001, max_iter=10000):\n",
        "    converged = False\n",
        "    iter = 0\n",
        "    N = x.shape[0]  # จำนวนตัวอย่าง (แนว row)\n",
        "    theta = np.random.random((x.shape[1], 1))  # ค่า theta เริ่มต้นด้วยค่า theta แบบสุ่ม\n",
        "\n",
        "    # ทำวนซ้ำเรื่อยๆ จะหยุดการทำงานเมื่อ 1.ค่า J < ค่า ep ที่กำหนด หรือจำนวนทำซ้ำ >= max_iter\n",
        "    while not converged:\n",
        "        for i in range(N):\n",
        "          #เลือกทุกคอลัมน์ในแถวที่ i ของเมทริกซ์หรืออาร์เรย์ x (xi ใดๆจะเป็นอาร์เรย์ 1 มิติ)\n",
        "          #และ.reshape เพื่อเปลี่ยนรูปอาร์เรย์ใหม่(จำนวนแถวใหม่=1, -1 คือ รักษาความยาวหรือคอลัมน์เดิมของอาร์เรย์)\n",
        "            xi = x[i, :].reshape(1, -1)  # เลือกข้อมูลแถวที่ i ของเมทริกซ์ x และเปลี่ยนรูปอาร์เรย์\n",
        "\n",
        "          #เลือกค่าของ y ที่ตำแหน่ง i ในอาร์เรย์ y (i เริ่มที่ 0)\n",
        "            yi = y[i]  # เลือกสมาชิกตัวที่ i เมทริกซ์ y\n",
        "\n",
        "          # คำนวณค่าคาดการณ์(y_hat)จากการคูณเมทริกซ์ระหว่าง xi และ theta\n",
        "            y_hat = xi.dot(theta)\n",
        "            diff = y_hat - yi # คำนวณความแตกต่าง diff ระหว่างค่าคาดการณ์(y_hat) และค่าจริง(yi)\n",
        "\n",
        "            grad = xi.T.dot(diff)\n",
        "            theta = theta - alpha * grad #อัปเดตค่า theta โดยใช้ gradient descent ในทุกๆตัวอย่าง xi ของชุดข้อมูล\n",
        "\n",
        "        # คำนวณค่า error หลังจากที่ได้ผ่านการประมวลผลข้อมูลทั้งหมดในชุดข้อมูลหนึ่งรอบ\n",
        "        J = cost_function(theta, x, y)\n",
        "\n",
        "        # ตรวจสอบการหยุดทำงาน\n",
        "        if J < ep or iter >= max_iter:\n",
        "            converged = True\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "    return theta"
      ],
      "metadata": {
        "id": "VLx7OpDhTV8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    # เพิ่มคอลัมน์ของค่า 1 intercept term เข้าไปในเมทริกซ์\n",
        "    x_b = np.c_[np.ones((x.shape[0], 1)), x]\n",
        "\n",
        "    # Learning rate\n",
        "    alpha = 0.01\n",
        "\n",
        "    # Train the model โดยใช้ SGD\n",
        "    theta = stochastic_gradient_descent(alpha, x_b, y, ep=0.001, max_iter=10000)\n",
        "    print(\"Theta = \", theta)\n",
        "\n",
        "    # พยากรณ์ค่าใหม่\n",
        "    xtest = np.array([[4, 9, 2, 3]])\n",
        "    xtest_b = np.c_[np.ones((xtest.shape[0], 1)), xtest]\n",
        "    y_p = xtest_b.dot(theta)\n",
        "    print(\"y predict = \", y_p)"
      ],
      "metadata": {
        "id": "Rax_1ayIrOUd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6ad0076-768c-4e7f-a7e1-e2d8e13d1269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theta =  [[ 2.51511774]\n",
            " [-1.37032574]\n",
            " [-0.01771878]\n",
            " [ 1.25980593]\n",
            " [ 2.35162359]]\n",
            "y predict =  [[6.44882838]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.2 Mini-Batch Gradient Descent (sampling:1 < n < N)"
      ],
      "metadata": {
        "id": "S_cU2fNPrH3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_function(theta, x, y):\n",
        "    y_hat = x.dot(theta)\n",
        "    c = (1/len(y)) * np.sum((y_hat - y) ** 2)\n",
        "    return c"
      ],
      "metadata": {
        "id": "270eL7I-UsFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mini_batch_gradient_descent(alpha, x, y, batch_size=20, ep=0.001, max_iter=10000):\n",
        "    converged = False\n",
        "    iter = 0\n",
        "    N = x.shape[0]  # จำนวนตัวอย่าง (แนว row)\n",
        "    theta = np.random.random((x.shape[1], 1))  # ค่า theta เริ่มต้นด้วยค่า theta แบบสุ่ม\n",
        "\n",
        "    while not converged:\n",
        "        # สุ่มลำดับข้อมูลในชุดข้อมูล x และค่าผลลัพธ์ y โดยการจัดเรียงข้อมูลใหม่\n",
        "        indices = np.arange(N)     # สร้างอาร์เรย์ที่ประกอบด้วยตัวเลขเรียงลำดับจาก 0 ถึง N-1\n",
        "        np.random.shuffle(indices) # สุ่มลำดับของตัวเลขในอาร์เรย์ indices\n",
        "        x_shuffled = x[indices]    # สร้างเมทริกซ์ x_shuffled ที่มีลำดับแถวที่สอดคล้องกับลำดับใน indices ที่ถูกสุ่ม\n",
        "        y_shuffled = y[indices]\n",
        "\n",
        "        for start in range(0, N, batch_size): # start=0,stop=N,step=batch_size\n",
        "            end = min(start + batch_size, N)  # ตำแหน่งสิ้นสุดของ batch จะถูกจำกัดโดยการใช้ min() ให้ไม่เกิน N\n",
        "            x_batch = x_shuffled[start:end]   # ข้อมูลที่ถูกสุ่มจัดเรียงใหม่\n",
        "            y_batch = y_shuffled[start:end]\n",
        "\n",
        "            # คำนวณตามสูตร\n",
        "            y_hat = x_batch.dot(theta)\n",
        "            diff = y_hat - y_batch\n",
        "\n",
        "            grad = x_batch.T.dot(diff) / len(y_batch)\n",
        "            theta = theta - alpha * grad\n",
        "\n",
        "        # คำนวณค่า error หลังจากที่ได้ผ่านการประมวลผลข้อมูลทั้งหมดในชุดข้อมูลหนึ่งรอบ\n",
        "        J = cost_function(theta, x, y)\n",
        "\n",
        "        # ตรวจสอบการหยุดทำงาน\n",
        "        if J < ep or iter >= max_iter:\n",
        "            converged = True\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "    return theta"
      ],
      "metadata": {
        "id": "H_coL34sUr0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    # เพิ่มคอลัมน์ของค่า 1 intercept term เข้าไปในเมทริกซ์\n",
        "    x_b = np.c_[np.ones((x.shape[0], 1)), x]\n",
        "\n",
        "    # Learning rate\n",
        "    alpha = 0.01\n",
        "\n",
        "    # Mini-batch size\n",
        "    batch_size = 2\n",
        "\n",
        "    # Train the model โดยใช้ Mini-batch Gradient Descent\n",
        "    theta = mini_batch_gradient_descent(alpha, x_b, y, batch_size=batch_size, ep=0.001, max_iter=10000)\n",
        "    print(\"Theta = \", theta)\n",
        "\n",
        "    # พยากรณ์ค่าใหม่\n",
        "    xtest = np.array([[4, 9, 2, 3]])\n",
        "    xtest_b = np.c_[np.ones((xtest.shape[0], 1)), xtest]\n",
        "    y_p = xtest_b.dot(theta)\n",
        "    print(\"y predict = \", y_p)"
      ],
      "metadata": {
        "id": "Ndv1QHjerPrr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e95301b1-58ff-406a-8be3-b773a95a09e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theta =  [[ 2.19840787]\n",
            " [-1.49343444]\n",
            " [ 0.04299918]\n",
            " [ 1.25717562]\n",
            " [ 2.55155775]]\n",
            "y predict =  [[6.78068721]]\n"
          ]
        }
      ]
    }
  ]
}